{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed2bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml\n",
    "import bs4\n",
    "import json\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c94d774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search_Engine_Comparison():\n",
    "    def __init__(self,url):\n",
    "        self.queries = []\n",
    "        self.url = url \n",
    "        self.result = {}\n",
    "        self.json_inp = {}\n",
    "        self.ref_json = {}\n",
    "        self.matches = {}\n",
    "        self.df = None\n",
    "        \n",
    "    def extract_input_queries(self):\n",
    "        with open('100QueriesSet2.txt',mode='r') as fopen:\n",
    "            self.queries = fopen.readlines()\n",
    "        self.queries = list(map(lambda q: q[0:len(q)-2],self.queries))\n",
    "    \n",
    "    def connect_to_bing_engine(self,queries):\n",
    "        for query in queries:\n",
    "            q = query.replace(\" \",\"+\")\n",
    "            q = q[0:len(q)]\n",
    "            full_url = self.url + q\n",
    "            req = requests.get(full_url)\n",
    "            soup = bs4.BeautifulSoup(req.text,\"lxml\")\n",
    "            content = soup.select(\".b_algo\")\n",
    "            if len(content) < 10:\n",
    "                full_url = full_url + \"&count=30\"\n",
    "                new_req = requests.get(full_url)\n",
    "                new_soup = bs4.BeautifulSoup(new_req.text,\"lxml\")\n",
    "                new_content = new_soup.select(\".b_algo\")\n",
    "                self.result[query] = new_content\n",
    "            else:\n",
    "                self.result[query] = content\n",
    "            sleep(5)\n",
    "            \n",
    "    def connect_to_yahoo_engine(self,queries):\n",
    "        for query in queries:\n",
    "            q = query.replace(\" \",\"+\")\n",
    "            q = q[0:len(q)]\n",
    "            i = 1\n",
    "            content = []\n",
    "            count = 0\n",
    "            while len(content) < 10:\n",
    "                if count == 5:\n",
    "                    break\n",
    "                full_url = self.url + q + '&b=' + str(i)\n",
    "                i += 1\n",
    "                req = requests.get(full_url)\n",
    "                soup = bs4.BeautifulSoup(req.text,\"lxml\")\n",
    "                content.extend(soup.find_all(\"a\",class_='d-ib fz-20 lh-26 td-hu tc va-bot mxw-100p'))\n",
    "                count += 1\n",
    "            self.result[query] = content\n",
    "            sleep(2)\n",
    "    \n",
    "    def process_bing_content(self):\n",
    "        for key,value in self.result.items():\n",
    "            links = []\n",
    "            for item in value:\n",
    "                links.append(item.select('a')[0]['href'])\n",
    "            self.json_inp[key] = links\n",
    "            \n",
    "    def process_yahoo_content(self):\n",
    "        for key,value in self.result.items():\n",
    "            links = []\n",
    "            for item in value:\n",
    "                links.append(item['href'])\n",
    "            self.json_inp[key] = links\n",
    "            \n",
    "    def generate_json_file(self):\n",
    "        with open(\"hw1.json\",mode=\"w\") as fopen:\n",
    "            json.dump(self.json_inp,fopen,indent=4)\n",
    "            \n",
    "    def extract_reference_search_result(self):\n",
    "        with open('Google_Result2.json',mode='r') as fopen:\n",
    "            self.ref_json = json.load(fopen)\n",
    "            \n",
    "    def generate_ranks(self):\n",
    "        # dictionary key = reference rank\n",
    "        # dictionary value = search result rank\n",
    "        for key,value in self.json_inp.items():\n",
    "            ref_res = self.ref_json.get(key)\n",
    "            if ref_res != None:\n",
    "                rank = []\n",
    "                for i in range(0,len(value)):\n",
    "                    pattern = value[i].replace('www.','')\n",
    "                    if pattern[0:5] == 'https':\n",
    "                        pattern = pattern[5:]\n",
    "                    elif pattern[0:4] == 'http':\n",
    "                        pattern = pattern[4:]\n",
    "                    if pattern[len(pattern)-1] == '/':\n",
    "                        pattern = pattern[0:len(pattern)-1]\n",
    "                    for j in range(0,len(ref_res)):\n",
    "                        if pattern in ref_res[j]:\n",
    "                            search_rank = i+1\n",
    "                            ref_rank = j+1\n",
    "                            rank.append((ref_rank,search_rank))\n",
    "                self.matches[key] = rank\n",
    "    \n",
    "    def calculate_score(self):\n",
    "        df_dat = []\n",
    "        avg_n = 0\n",
    "        avg_perc = 0\n",
    "        avg_coeff = 0\n",
    "        for key,value in self.matches.items():\n",
    "            index = self.queries.index(key)+1\n",
    "            n = len(value)\n",
    "            if n > 0:\n",
    "                avg_n += n\n",
    "                overlap_perc = (len(value)/10)*100\n",
    "                avg_perc += overlap_perc\n",
    "                if n == 1:\n",
    "                    ref,srch = value[0]\n",
    "                    if ref == srch:\n",
    "                        rho = 1\n",
    "                    else:\n",
    "                        rho = 0\n",
    "                else:\n",
    "                    n = len(value)\n",
    "                    dist_sum = 0\n",
    "                    for ref,srch in value:\n",
    "                        dist_sum += (ref-srch)**2\n",
    "                    rho = 1 - ((6*dist_sum)/(n*((n**2)-1)))\n",
    "                avg_coeff += rho\n",
    "                df_dat.append(['Query '+str(index),n,overlap_perc,rho])\n",
    "        size = len(df_dat)\n",
    "        df_dat.append(['Averages',avg_n/size,avg_perc/size,avg_coeff/size])\n",
    "        self.df = pd.DataFrame(df_dat,columns=['Queries','Number of Overlapping Results','Percent Overlap','Spearman Coefficient'])\n",
    "        \n",
    "    def generate_csv_file(self):\n",
    "        self.df.to_csv('hw1.csv',index=False)\n",
    "        \n",
    "    def start_comparison(self):\n",
    "        self.extract_input_queries()\n",
    "        self.extract_reference_search_result()\n",
    "        engine = input(\"enter the search engine to be used: \")\n",
    "        if engine.lower() == 'bing':\n",
    "            i=0\n",
    "            while i < 100:\n",
    "                self.connect_to_bing_engine(self.queries[i:i+10])\n",
    "                i = i+10\n",
    "            self.process_bing_content()\n",
    "        elif engine.lower() == 'yahoo':\n",
    "            self.connect_to_yahoo_engine(self.queries)\n",
    "            self.process_yahoo_content()\n",
    "        self.generate_json_file()\n",
    "        self.generate_ranks()\n",
    "        self.calculate_score()\n",
    "        self.generate_csv_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde81c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo = Search_Engine_Comparison('https://search.yahoo.com/search?p=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2db0470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the search engine to be used: yahoo\n"
     ]
    }
   ],
   "source": [
    "yahoo.start_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347593bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
